{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "FEATURE SELECTION TECHNIQUES AND WHY FEATURE SELECTION IS IMPORTANT.\n",
    "Importance of feature selection.\n",
    "1. Helps prevent overfitting in models.\n",
    "2. Will increase efficiency of the model.\n",
    "3. Reduce training time.\n",
    "4. Help boost generalization of models.\n",
    "5. Minimize collinearity while enhancing interpretability.\n",
    "6. Helps avoid the hectiness of dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Univariate selection.\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 110.73 1406.59   17.5    51.01 2219.4   127.67    5.36  178.01]\n",
      "\n",
      " Featured Data: \n",
      " [[ 85.    0.   26.6  31. ]\n",
      " [183.    0.   23.3  32. ]\n",
      " [ 89.   94.   28.1  21. ]\n",
      " [137.  168.   43.1  33. ]]\n"
     ]
    }
   ],
   "source": [
    "path = 'pima-indians-diabetes.csv'\n",
    "df = read_csv(path)\n",
    "array = df.values\n",
    "\n",
    "#Separate array into input and output components.\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "test = SelectKBest(score_func = chi2, k=4)\n",
    "fit = test.fit(X,Y)\n",
    "set_printoptions(precision = 2)\n",
    "print(fit.scores_)\n",
    "\n",
    "featured_data = fit.transform(X)\n",
    "print(\"\\n Featured Data: \\n\", featured_data[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature selection, we will use the sciKit Learn (popularly known as Sklearn).\n",
    "In this tutorial we will use sklearn to:\n",
    "1. Remove features with low variance.\n",
    "2. Select Kbest features.\n",
    "3. Select feature by other model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove low variance features.\n",
    "import sklearn.feature_selection as fs\n",
    "\n",
    "# X is you feature matrix\n",
    "var = fs.VarianceThreshold(threshold=0.2)\n",
    "#Threshold allows you to control your variance.\n",
    "var.fit(X)\n",
    "X_trans = var.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data\n",
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 1]\n",
      " [0 1 0]\n",
      " [0 1 1]]\n",
      "The processed data by variance threshold\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Let's see an actaual implementation of VarianceThreshold.\n",
    "import sklearn.feature_selection as fs\n",
    "import numpy as np \n",
    "\n",
    "X = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1,\n",
    "                                                                      1]])\n",
    "var = fs.VarianceThreshold(threshold=0.2)\n",
    "var.fit(X)\n",
    "X_trans = var.transform(X)\n",
    "print(\"The original data\")\n",
    "print(X)\n",
    "print(\"The processed data by variance threshold\")\n",
    "print(X_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "sklearn.feature_selection import SelectKBest, f_classif\n",
    "X, y = datasets.make_classification(n_samples=300, n_features=10, n_informative=4)\n",
    "# choose the f_classif as the metric and K is 3\n",
    "bk = SelectKBest(f_classif,k=3)\n",
    "bk.fit(X, y)\n",
    "X_trans = bk.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_selection as fs\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = datasets.make_classification(n_samples=500,\n",
    "                                    n_features=20,\n",
    "                                    n_informative=8,\n",
    "                                    random_state=42)\n",
    "\n",
    "f1_list = []\n",
    "for k in range(1, 15):\n",
    "    bk = SelectKBest(f_classif,k=k)\n",
    "    bk.fit(X, y)\n",
    "    X_trans = bk.transform(X)\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X_trans,\n",
    "                                                        y,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train_x, train_y)\n",
    "    y_pred = lr.predict(test_x)\n",
    "    f1 = metrics.f1_score(test_y, y_pred)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "fig, axe = plt.subplots(dpi = 300)\n",
    "axe.plot(range(1, 15), f1_list)\n",
    "axe.set_xlabel(\"best k features\")\n",
    "axe.set_ylabel(\"F1-score\")\n",
    "fig.savefig(\"output/img.png\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d535c1a89bc2325fb7e4e0b65b381789fada57f120444c0dba78f05ecce83dee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
